{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, os, glob, matplotlib.pyplot as plt, pandas as pd, colorcet, matplotlib as mpl\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import miniball\n",
    "from scipy.ndimage import binary_dilation, binary_erosion\n",
    "from skimage.measure import label\n",
    "import shapely.ops, shapely.geometry as geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS_CLUSTERS = {\n",
    " 'walk': '#0072b2',\n",
    " 'one-leg-after-other': '#eee8c7',\n",
    " 'extrude-slow': '#f0e442',\n",
    " 'extrude': '#009e73',\n",
    " 'left-leg': '#e69f00',\n",
    " 'both-legs': '#ccc8a7',\n",
    " 'stationary': '#000000',\n",
    " 'stationary-posterior': '#666666',\n",
    " 'stationary-anterior': '#666666',\n",
    " 'stabilimentum': '#cc79a7',\n",
    " 'noisy': None,\n",
    " 'right-leg': '#56b4e9',\n",
    " 'bend-abdomen': '#d55e00'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnameP = 'Z:/behavior/*/wavelet/rawmvmt_dlc_euclidean-midline_no-abspos_no-vel_00000000010001000000010001_60_16_meansub_scalestd_hipow_tsne_no-pca_perplexity_100_200000_2000_euclidean.clusters.npy'\n",
    "fnameA = 'rawmvmt_dlc_euclidean_no-abspos_no-vel_00000010001000000010001000_60_16_meansub_scalestd_hipow_tsne_no-pca_perplexity_100_200000_2000_euclidean.clusters.npy'\n",
    "\n",
    "fnamesP = [x for x in glob.glob(fnameP) if 'RIG' not in x]\n",
    "fnamesA = [os.path.join(os.path.dirname(x), fnameA) for x in fnamesP]\n",
    "len(fnamesP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGE_MANUAL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrClustersP = [np.load(x)[:,0] for x in fnamesP]\n",
    "arrClustersA = [np.load(x)[:,0] for x in fnamesA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrUsetsP = [np.all(~np.isnan(np.load(x.replace('.clusters.npy', '.npy'))), axis=1) for x in fnamesP]\n",
    "arrUsetsA = [np.all(~np.isnan(np.load(x.replace('.clusters.npy', '.npy'))), axis=1) for x in fnamesA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrTsneP = [np.load(x.replace('.clusters.npy', '.filtered2.npy'))[:, 2:4] for x in fnamesP]\n",
    "arrTsneA = [np.load(x.replace('.clusters.npy', '.filtered2.npy'))[:, 2:4] for x in fnamesA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toNumber(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except:\n",
    "        return -1\n",
    "    \n",
    "def loadLabels(fnameLabels):\n",
    "    txtClusterLabels = ''\n",
    "    with open(fnameLabels, 'r') as f:\n",
    "        txtClusterLabels = f.read()\n",
    "    clusterLabels = {}\n",
    "    curLabel = ''\n",
    "    for line in txtClusterLabels.split('\\n'):\n",
    "        if ':' in line:\n",
    "            curLabel = line[:line.find(':')]\n",
    "        elif len(line.strip()) > 0:\n",
    "            clusterLabels[curLabel] = [toNumber(x) for x in line.split(',') if toNumber(x) >= 0]\n",
    "    return clusterLabels\n",
    "\n",
    "ANTERIOR = 1\n",
    "POSTERIOR = 0\n",
    "\n",
    "fnameClusterLabelsA = '\\\\\\\\?\\\\Y:\\\\wavelet\\\\clips\\\\rawmvmt_dlc_euclidean_no-abspos_no-vel_00000010001000000010001000_60_16_meansub_scalestd\\\\cluster_names.txt'\n",
    "fnameClusterLabelsP = '\\\\\\\\?\\\\Y:\\\\wavelet\\\\clips\\\\rawmvmt_dlc_euclidean-midline_no-abspos_no-vel_00000000010001000000010001_60_16_meansub_scalestd\\\\cluster_names.txt'\n",
    "clusterLabelsAmanual = loadLabels(fnameClusterLabelsA)\n",
    "clusterLabelsPmanual = loadLabels(fnameClusterLabelsP)\n",
    "del clusterLabelsAmanual['noisy']\n",
    "del clusterLabelsPmanual['noisy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnameSharedTsneP = '\\\\\\\\?\\\\Y:\\\\wavelet\\\\rawmvmt_dlc_euclidean-midline_no-abspos_no-vel_00000000010001000000010001_60_16_meansub_scalestd\\\\rawmvmt_dlc_euclidean-midline_no-abspos_no-vel_00000000010001000000010001_60_16_meansub_scalestd_hipow_tsne_no-pca_perplexity_100_200000_2000_euclidean.smoothed.watershed.npy'\n",
    "fnameSharedTsneA = '\\\\\\\\?\\\\Y:\\\\wavelet\\\\rawmvmt_dlc_euclidean_no-abspos_no-vel_00000010001000000010001000_60_16_meansub_scalestd\\\\rawmvmt_dlc_euclidean_no-abspos_no-vel_00000010001000000010001000_60_16_meansub_scalestd_hipow_tsne_no-pca_perplexity_100_200000_2000_euclidean.smoothed.watershed.npy'\n",
    "arrSharedTsneP = np.load(fnameSharedTsneP)[:, :, 0, 1].astype(int)\n",
    "arrSharedTsneA = np.load(fnameSharedTsneA)[:, :, 0, 1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitManualLabelsFromContiguity(clusterLabelsManual, arrSharedTsne, mergeManual=True):\n",
    "    clusterLabels = {}\n",
    "    for key in clusterLabelsManual:\n",
    "        for clid in clusterLabelsManual[key]:\n",
    "            clusterLabels['{}-{}'.format(key, clid)] = (arrSharedTsne == clid, [clid, ])\n",
    "\n",
    "    if mergeManual:\n",
    "        # Now aggregate contiguous clusters\n",
    "        #    (keep aggregating until no changes occur)\n",
    "        while True:\n",
    "            match = False\n",
    "            for key1 in clusterLabels:\n",
    "                for key2 in clusterLabels:\n",
    "                    if key1 != key2:\n",
    "                        base1 = key1[:key1.rfind('-')]\n",
    "                        base2 = key2[:key2.rfind('-')]\n",
    "                        if base1 == base2:\n",
    "                            if np.sum(clusterLabels[key1][0] & binary_dilation(clusterLabels[key2][0], iterations=1)) > 0:\n",
    "                                match = True\n",
    "                                clusterLabels[key1] = (clusterLabels[key1][0] | clusterLabels[key2][0], \n",
    "                                                       clusterLabels[key1][1] + clusterLabels[key2][1])\n",
    "                                del clusterLabels[key2]\n",
    "                                break\n",
    "                if match:\n",
    "                    break\n",
    "            if not match:\n",
    "                break\n",
    "            \n",
    "    return clusterLabels, {k:v[1] for k, v in clusterLabels.items()}\n",
    "\n",
    "clusterLabelsAcl, clusterLabelsA = splitManualLabelsFromContiguity(\n",
    "    clusterLabelsAmanual, arrSharedTsneA, mergeManual=MERGE_MANUAL)\n",
    "clusterLabelsPcl, clusterLabelsP = splitManualLabelsFromContiguity(\n",
    "    clusterLabelsPmanual, arrSharedTsneP, mergeManual=MERGE_MANUAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert cluster IDs to manual cluster IDs\n",
    "arrClustersAmanual = [[([i for i, k in enumerate(list(clusterLabelsA.keys())) if \\\n",
    "    int(y) in clusterLabelsA[k]] + [np.nan,])[0] for y in x] for x in tqdm(arrClustersA, leave=False)]\n",
    "arrClustersPmanual = [[([i for i, k in enumerate(list(clusterLabelsP.keys())) if \\\n",
    "    int(y) in clusterLabelsP[k]] + [np.nan,])[0] for y in x] for x in tqdm(arrClustersP, leave=False)]\n",
    "\n",
    "arrClustersAmanualNoNA = [pd.DataFrame(x).fillna(method='ffill').fillna(\n",
    "    method='bfill').values[:,0].astype(int) for x in arrClustersAmanual]\n",
    "arrClustersPmanualNoNA = [pd.DataFrame(x).fillna(method='ffill').fillna(\n",
    "    method='bfill').values[:,0].astype(int) for x in arrClustersPmanual]\n",
    "\n",
    "arrClustersAmanual = [np.array([(-1 if np.isnan(y) else y) for y in x]).astype(int) for x in arrClustersAmanual]\n",
    "arrClustersPmanual = [np.array([(-1 if np.isnan(y) else y) for y in x]).astype(int) for x in arrClustersPmanual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEmbeddingStable(x):\n",
    "    a = [[],]\n",
    "    for i, c in enumerate(x):\n",
    "        if len(a[-1]) == 0 or c == a[-1][-1]:\n",
    "            a[-1] = a[-1] + [c,]\n",
    "        else:\n",
    "            a.append([c,])\n",
    "    a = [np.full(len(x), len(x)>=12, dtype=np.bool) for x in a]\n",
    "    return np.hstack(a)\n",
    "arrStableA = [isEmbeddingStable(x) for x in tqdm(arrClustersAmanual, leave=False)]\n",
    "arrStableP = [isEmbeddingStable(x) for x in tqdm(arrClustersPmanual, leave=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keepStable(x, st):\n",
    "    x2 = x.copy().astype(np.float64)\n",
    "    x2[~st] = np.nan\n",
    "    x2[x2 < 0] = np.nan\n",
    "    return x2\n",
    "\n",
    "arrClustersAmanualStableNoNA = [pd.DataFrame(keepStable(x, st)).fillna(method='ffill').fillna(\n",
    "    method='bfill').values[:,0].astype(int) for x, st in zip(arrClustersAmanual, arrStableA)]\n",
    "arrClustersPmanualStableNoNA = [pd.DataFrame(keepStable(x, st)).fillna(method='ffill').fillna(\n",
    "    method='bfill').values[:,0].astype(int) for x, st in zip(arrClustersPmanual, arrStableP)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxJumpA = [np.argwhere(np.diff(x) != 0)[:,0] for x in arrClustersAmanualNoNA]\n",
    "idxJumpStableA = [np.argwhere(np.diff(x) != 0)[:,0] for x in arrClustersAmanualStableNoNA]\n",
    "\n",
    "idxJumpP = [np.argwhere(np.diff(x) != 0)[:,0] for x in arrClustersPmanualNoNA]\n",
    "idxJumpStableP = [np.argwhere(np.diff(x) != 0)[:,0] for x in arrClustersPmanualStableNoNA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jumpDistsA = [np.linalg.norm(tsne[jumps] - tsne[jumps+1], axis=1) for tsne, jumps in zip(arrTsneA, idxJumpA)]\n",
    "jumpDistsStableA = [np.linalg.norm(tsne[jumps] - tsne[jumps+1], axis=1) for tsne, jumps in zip(arrTsneA, idxJumpStableA)]\n",
    "\n",
    "jumpDistsP = [np.linalg.norm(tsne[jumps] - tsne[jumps+1], axis=1) for tsne, jumps in zip(arrTsneP, idxJumpP)]\n",
    "jumpDistsStableP = [np.linalg.norm(tsne[jumps] - tsne[jumps+1], axis=1) for tsne, jumps in zip(arrTsneP, idxJumpStableP)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densTsneA = [np.histogram2d(x[:,0], x[:,1], bins=(200, 200), range=((0, 1), (0, 1)))[0] for x in arrTsneA]\n",
    "densTsneP = [np.histogram2d(x[:,0], x[:,1], bins=(200, 200), range=((0, 1), (0, 1)))[0] for x in arrTsneP]\n",
    "\n",
    "densTsneA = [x / np.max(x) for x in densTsneA]\n",
    "densTsneP = [x / np.max(x) for x in densTsneP]\n",
    "\n",
    "densTsneA = np.mean(densTsneA, axis=0)\n",
    "densTsneP = np.mean(densTsneP, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax[0].imshow(densTsneP > np.max(densTsneP) * 0.001)\n",
    "ax[1].imshow(densTsneA > np.max(densTsneA) * 0.001)\n",
    "ax[0].set_title('Posterior Density > 0.1% of max')\n",
    "ax[1].set_title('Anterior Density > 0.1% of max')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute diameter of circle around the representative tSNE mass \n",
    "maxJumpA = 2 * np.sqrt(miniball.Miniball(np.argwhere(densTsneA > np.max(densTsneA) * 0.001)).squared_radius()) / 200.0\n",
    "maxJumpP = 2 * np.sqrt(miniball.Miniball(np.argwhere(densTsneP > np.max(densTsneP) * 0.001)).squared_radius()) / 200.0\n",
    "maxJumpA, maxJumpP\n",
    "# = (0.550, 0.597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binsDistsA = np.histogram(np.hstack(jumpDistsA), bins='fd', range=(0, maxJumpA))[0].size\n",
    "binsDistsP = np.histogram(np.hstack(jumpDistsP), bins='fd', range=(0, maxJumpP))[0].size\n",
    "\n",
    "binsDistsStableA = np.histogram(np.hstack(jumpDistsStableA), bins='fd', range=(0, maxJumpA))[0].size\n",
    "binsDistsStableP = np.histogram(np.hstack(jumpDistsStableP), bins='fd', range=(0, maxJumpP))[0].size\n",
    "\n",
    "binsDistsA = max(binsDistsA, binsDistsStableA)\n",
    "binsDistsStableA = binsDistsA\n",
    "\n",
    "binsDistsP = max(binsDistsP, binsDistsStableP)\n",
    "binsDistsStableP = binsDistsP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histDistsA = [np.histogram(x, bins=binsDistsA, range=(0, maxJumpA))[0] for x in jumpDistsA]\n",
    "histDistsP = [np.histogram(x, bins=binsDistsP, range=(0, maxJumpP))[0] for x in jumpDistsP]\n",
    "\n",
    "histDistsStableA = [np.histogram(x, bins=binsDistsStableA, range=(0, maxJumpA))[0] for x in jumpDistsStableA]\n",
    "histDistsStableP = [np.histogram(x, bins=binsDistsStableP, range=(0, maxJumpP))[0] for x in jumpDistsStableP]\n",
    "\n",
    "histDistsA = [x / np.sum(x) for x in histDistsA]\n",
    "histDistsP = [x / np.sum(x) for x in histDistsP]\n",
    "\n",
    "histDistsStableA = [x / np.sum(x) for x in histDistsStableA]\n",
    "histDistsStableP = [x / np.sum(x) for x in histDistsStableP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "m = np.median(np.array(histDistsStableA), axis=0)\n",
    "s0 = np.percentile(np.array(histDistsStableA), 25, axis=0)\n",
    "s1 = np.percentile(np.array(histDistsStableA), 75, axis=0)\n",
    "ax[0].fill_between(np.linspace(0, 1, binsDistsStableA), s0, s1, color='gray', alpha=0.25)\n",
    "ax[0].plot(np.linspace(0, 1, binsDistsStableA), m, color='red')\n",
    "\n",
    "m = np.median(np.array(histDistsA), axis=0)\n",
    "s0 = np.percentile(np.array(histDistsA), 25, axis=0)\n",
    "s1 = np.percentile(np.array(histDistsA), 75, axis=0)\n",
    "ax[0].fill_between(np.linspace(0, 1, binsDistsA), s0, s1, color='gray', alpha=0.25)\n",
    "ax[0].plot(np.linspace(0, 1, binsDistsA), m, color='blue')\n",
    "\n",
    "ax[0].set_title('Anterior Jumps (Stable=Red)')\n",
    "\n",
    "m = np.median(np.array(histDistsStableP), axis=0)\n",
    "s0 = np.percentile(np.array(histDistsStableP), 25, axis=0)\n",
    "s1 = np.percentile(np.array(histDistsStableP), 75, axis=0)\n",
    "ax[1].fill_between(np.linspace(0, 1, binsDistsStableP), s0, s1, color='gray', alpha=0.25)\n",
    "ax[1].plot(np.linspace(0, 1, binsDistsStableP), m, color='red')\n",
    "\n",
    "m = np.median(np.array(histDistsP), axis=0)\n",
    "s0 = np.percentile(np.array(histDistsP), 25, axis=0)\n",
    "s1 = np.percentile(np.array(histDistsP), 75, axis=0)\n",
    "ax[1].fill_between(np.linspace(0, 1, binsDistsP), s0, s1, color='gray', alpha=0.25)\n",
    "ax[1].plot(np.linspace(0, 1, binsDistsP), m, color='blue')\n",
    "\n",
    "ax[1].set_title('Posterior Jumps (Stable=Red)')\n",
    "\n",
    "ax[0].set_ylabel('PDF')\n",
    "\n",
    "ax[0].set_xlabel('Transition Jump Distance in t-SNE space, \\nNormalized to Diameter of t-SNE Density Outline')\n",
    "ax[1].set_xlabel('Transition Jump Distance in t-SNE space, \\nNormalized to Diameter of t-SNE Density Outline')\n",
    "\n",
    "fig.show()\n",
    "#fig.savefig('C:/Users/acorver/Desktop/paper-figures/transitions_distribution.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTransitionMatrix(seqAll, idx, N=None):\n",
    "    seq = seqAll[idx]\n",
    "    if N is None:\n",
    "        N = np.max([np.max(x) for x in seqAll]) + 1\n",
    "    mtx = np.zeros((N, N), dtype=np.float64)\n",
    "    for i in range(1, len(seq)):\n",
    "        if seq[i] != seq[i-1]:\n",
    "            mtx[seq[i-1], seq[i]] += 1\n",
    "    mtxRates = mtx.copy()\n",
    "    for k in range(mtx.shape[0]):\n",
    "        if np.sum(mtx[k, :]) > 0:\n",
    "            mtx[k, :] = mtx[k, :] / np.sum(mtx[k, :])\n",
    "    return mtx, mtxRates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitionMtxA = [getTransitionMatrix(arrClustersAmanualNoNA, i, \n",
    "    np.max([np.max(x)+1 for x in arrClustersAmanualNoNA])) for i in tqdm(\n",
    "    range(len(arrClustersAmanualNoNA)), leave=False)]\n",
    "transitionMtxP = [getTransitionMatrix(arrClustersPmanualNoNA, i,\n",
    "    np.max([np.max(x)+1 for x in arrClustersPmanualNoNA])) for i in tqdm(\n",
    "    range(len(arrClustersPmanualNoNA)), leave=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitionMtxArates = [x[1] for x in transitionMtxA]\n",
    "transitionMtxA      = [x[0] for x in transitionMtxA]\n",
    "transitionMtxPrates = [x[1] for x in transitionMtxP]\n",
    "transitionMtxP      = [x[0] for x in transitionMtxP]\n",
    "\n",
    "transitionMtxA = np.mean(transitionMtxA, axis=0)\n",
    "transitionMtxP = np.mean(transitionMtxP, axis=0)\n",
    "\n",
    "transitionMtxArates = np.mean(transitionMtxArates, axis=0)\n",
    "transitionMtxPrates = np.mean(transitionMtxPrates, axis=0)\n",
    "\n",
    "# Renormalize (only affects small number of rows)\n",
    "transitionMtxA /= np.sum(transitionMtxA, axis=1)[:, np.newaxis]\n",
    "transitionMtxP /= np.sum(transitionMtxP, axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitionMtxA[np.isnan(transitionMtxA)] = 0\n",
    "transitionMtxP[np.isnan(transitionMtxP)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrWatershedA = np.load(fnameSharedTsneA)\n",
    "arrWatershedP = np.load(fnameSharedTsneP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaksA = np.array([np.median(np.vstack(arrTsneA)[np.isin(np.hstack(\n",
    "    arrClustersAmanualNoNA), k), :], axis=0) for k in tqdm(range(transitionMtxA.shape[0]), leave=False)])\n",
    "peaksP = np.array([np.median(np.vstack(arrTsneP)[np.isin(np.hstack(\n",
    "    arrClustersPmanualNoNA), k), :], axis=0) for k in tqdm(range(transitionMtxP.shape[0]), leave=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load densities\n",
    "Hs = []\n",
    "for arr in arrTsneA:\n",
    "    arr = arr[~np.any(np.isnan(arr), axis=1)]\n",
    "    H, _, _ = np.histogram2d(arr[:,0], arr[:,1], bins=(200,200), range=((0, 1), (0, 1)))\n",
    "    H = np.clip(H, 0, np.percentile(H, 99))\n",
    "    Hs.append(H)\n",
    "densityA = np.mean(Hs, axis=0)\n",
    "\n",
    "Hs = []\n",
    "for arr in arrTsneP:\n",
    "    arr = arr[~np.any(np.isnan(arr), axis=1)]\n",
    "    H, _, _ = np.histogram2d(arr[:,0], arr[:,1], bins=(200,200), range=((0, 1), (0, 1)))\n",
    "    H = np.clip(H, 0, np.percentile(H, 99))\n",
    "    Hs.append(H)\n",
    "densityP = np.mean(Hs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskToPerimeter(mask):\n",
    "    mask[0,:] = False\n",
    "    mask[-1,:] = False\n",
    "    mask[:,0] = False\n",
    "    mask[:,-1] = False\n",
    "    \n",
    "    polys = [geom.Polygon([[_x + dx, _y + dy] for dx, dy in [[0,0],[0,1],[1,1],[1,0]]]) for _x, _y in \\\n",
    "         np.argwhere(mask)]\n",
    "    a = shapely.ops.cascaded_union(polys).exterior.coords.xy\n",
    "    xy = np.hstack((np.array(a[0])[:,np.newaxis], np.array(a[1])[:,np.newaxis]))\n",
    "    \n",
    "    return xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorcet\n",
    "import matplotlib.colors\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "class customColormap(matplotlib.colors.LinearSegmentedColormap):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.baseCM = cm.get_cmap('cet_CET_L19')\n",
    "        self.N = self.baseCM.N\n",
    "    def __call__(self, r, *args, **kwargs):\n",
    "        def mapColor(x):\n",
    "            _c = self.baseCM(0.0, *args, **kwargs)\n",
    "            lim = 0.10\n",
    "            if x >= lim:\n",
    "                return self.baseCM((x-lim)/(1.0 - lim), *args, **kwargs)\n",
    "            else: \n",
    "                if isinstance(_c[0], float):\n",
    "                    z = (x / lim)\n",
    "                    a = _c[0] * z + 1.0 * (1 - z)\n",
    "                    b = _c[1] * z + 1.0 * (1 - z)\n",
    "                    c = _c[2] * z + 1.0 * (1 - z)\n",
    "                    _c = (a, b, c, 1.0)\n",
    "                    return _c\n",
    "                else:\n",
    "                    z = (x / lim)\n",
    "                    a = int(_c[0] * z + 255.0 * (1 - z))\n",
    "                    b = int(_c[1] * z + 255.0 * (1 - z))\n",
    "                    c = int(_c[2] * z + 255.0 * (1 - z))\n",
    "                    _c = (a, b, c, 255)\n",
    "                    return _c\n",
    "        if r.ndim == 2:\n",
    "            _c = self.baseCM(0.0, *args, **kwargs)\n",
    "            cs = np.array([[mapColor(y) for y in x] for x in r], \n",
    "                dtype=np.float64 if isinstance(_c[0], float) else np.uint8)\n",
    "            return cs\n",
    "        elif r.ndim == 1:\n",
    "            _c = self.baseCM(0.0, *args, **kwargs)\n",
    "            cs = np.array([mapColor(y) for y in r], \n",
    "                dtype=np.float64 if isinstance(_c[0], float) else np.uint8)\n",
    "            return cs\n",
    "        else:\n",
    "            print('!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "probThreshold = 0.05\n",
    "cmDensity = plt.get_cmap('cet_CET_L19') #customColormap()\n",
    "\n",
    "def plot(ax, anterior):\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    transitionsPlt = (transitionMtxA if anterior else transitionMtxP).copy().astype(np.float64)\n",
    "    transitionsRate= (transitionMtxArates if anterior else transitionMtxPrates).copy().astype(np.float64)\n",
    "    peaks = (peaksA if anterior else peaksP) * 200\n",
    "    density = (densityA if anterior else densityP)\n",
    "    clusterLabels = (clusterLabelsA if anterior else clusterLabelsP)\n",
    "    arrWatershed = (arrWatershedA if anterior else arrWatershedP)\n",
    "    \n",
    "    # Plot density\n",
    "    _dens = np.flip(density, axis=0)\n",
    "    _dens = np.clip(_dens, 0, np.percentile(_dens, 99.9))\n",
    "    _dens/= _dens.max()\n",
    "    ax.imshow(_dens, extent=(0, 200, 0, 200), cmap=cmDensity)\n",
    "    \n",
    "    # Plot cluster boundaries\n",
    "    for z in range(0, 2):\n",
    "        for k, clusterIDsKey in enumerate([x for x in clusterLabels if x != 'noisy']):\n",
    "            clusterIDs = clusterLabels[clusterIDsKey]\n",
    "            # Plot clusters to highlight\n",
    "            mask = None\n",
    "            for exID, clusterID in enumerate(clusterIDs):\n",
    "                _mask = (arrWatershed[:,:,0,1] == clusterID)\n",
    "                # Merge masks\n",
    "                mask = _mask if mask is None else (mask | _mask)\n",
    "\n",
    "            # Split masks into contiguous submasks\n",
    "            maskLabeled = label(binary_dilation(binary_erosion(mask, iterations=1), iterations=1))\n",
    "            maskLabeledBg = np.max([np.sum(maskLabeled == x) for x in np.unique(maskLabeled)])\n",
    "            isLabeled = False\n",
    "            for maskID in np.unique(maskLabeled):\n",
    "                if np.sum(maskLabeled == maskID) != maskLabeledBg:\n",
    "                    mask = (maskLabeled == maskID)\n",
    "                    mask[:25,:] = False\n",
    "                    mask[175:,:] = False\n",
    "                    mask[:,:25] = False\n",
    "                    mask[:,175:] = False\n",
    "                    pts = maskToPerimeter(mask)\n",
    "                    if pts is not None:\n",
    "                        clusterIDsKeyBase = re.search('.*(?=-[0-9]*)', clusterIDsKey).group(0)\n",
    "                        ax.plot(pts[:,1], pts[:,0], linewidth=2, \\\n",
    "                            color=COLORS_CLUSTERS[clusterIDsKeyBase] + '88')\n",
    "                        ax.fill(pts[:,1], pts[:,0], linewidth=1, \\\n",
    "                            edgecolor=COLORS_CLUSTERS[clusterIDsKeyBase], \n",
    "                            facecolor=COLORS_CLUSTERS[clusterIDsKeyBase] + '11')\n",
    "                        isLabeled = True\n",
    "\n",
    "    # Sort arrows to plot by increasing thickness\n",
    "    ijs = np.array(sorted(np.argwhere(transitionsPlt), key=lambda x: transitionsPlt[x[0],x[1]]))\n",
    "        \n",
    "    for (i, j) in ijs:\n",
    "        if transitionsPlt[i,j] >= probThreshold and transitionsRate[i,j] >= 10: \n",
    "            try:\n",
    "                ax.annotate(\"\",\n",
    "                    xy=(peaks[i,1],peaks[i,0]), xycoords='data',\n",
    "                    xytext=(peaks[j,1],peaks[j,0]), textcoords='data',\n",
    "                    arrowprops=dict(\n",
    "                        arrowstyle=\"-\", color=\"#222222\",\n",
    "                        shrinkA=5, shrinkB=5,\n",
    "                        patchA=None, patchB=None,\n",
    "                        connectionstyle='arc3, rad=0.2',\n",
    "                        linewidth=transitionsPlt[i, j] * 10\n",
    "                        ))\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            \n",
    "    for p in range(peaks.shape[0]):\n",
    "        ax.scatter(peaks[p,1], peaks[p,0], color='#ff3333', s=7)\n",
    "    \n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 8))\n",
    "\n",
    "ax[0].set_title('Anterior Transitions (>= {})'.format(probThreshold))\n",
    "plot(ax[0], True)\n",
    "ax[0].set_xlim(25, 175)\n",
    "ax[0].set_ylim(25, 175)\n",
    "\n",
    "ax[1].set_title('Posterior Transitions (>= {})'.format(probThreshold))\n",
    "plot(ax[1], False)\n",
    "ax[1].set_xlim(25, 175)\n",
    "ax[1].set_ylim(25, 175)\n",
    "\n",
    "# Plot legend\n",
    "ax[2].set_axis_off()\n",
    "ax[2].set_xlim(25, 175)\n",
    "ax[2].set_ylim(25, 175)\n",
    "\n",
    "for z, (p, invert) in enumerate([(0.1, True), (0.1, False), (0.5, False), (1.0, False)]):\n",
    "    x1, y1, x2, y2 = 30, 80 + z * 20, 50, 80 + z * 20\n",
    "    if invert:\n",
    "        a, b = x1, y1\n",
    "        x1, y1 = x2, y2\n",
    "        x2, y2 = a, b\n",
    "    ax[2].scatter(x1, y1, color='#ff3333', s=20, zorder=10)\n",
    "    ax[2].scatter(x2, y2, color='#ff3333', s=20, zorder=10)\n",
    "    ax[2].annotate(\"\",\n",
    "        xy=(x1, y1), xycoords='data',\n",
    "        xytext=(x2, y2), textcoords='data',\n",
    "        arrowprops=dict(\n",
    "            arrowstyle=\"-\", color=\"#222222\",\n",
    "            shrinkA=3 * p, shrinkB=5 * p,\n",
    "            patchA=None, patchB=None,\n",
    "            connectionstyle='arc3, rad=0.2',\n",
    "            linewidth=p * 10\n",
    "            ))\n",
    "    ax[2].text(min(x1, x2), y1 + 6, 'A', ha='center', fontsize=16)\n",
    "    ax[2].text(max(x1, x2), y2 + 6, 'B', ha='center', fontsize=16)\n",
    "    ax[2].text(max(x1, x2) + 20, y2, 'P({}) = {}'.format(\n",
    "        'B → A' if invert else 'A → B', p), ha='left', va='center', fontsize=16)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('C:/Users/acorver/Desktop/paper-figures/transitions_arrows_v2_{}{}.pdf'.format(\n",
    "    probThreshold, '_mergemanual' if MERGE_MANUAL else ''), bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot(ax, anterior):\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    transitionsPlt = (transitionMtxA if anterior else transitionMtxP).copy().astype(np.float64)\n",
    "    transitionsRate= (transitionMtxArates if anterior else transitionMtxPrates).copy().astype(np.float64)\n",
    "    peaks = (peaksA if anterior else peaksP) * 200\n",
    "    density = (densityA if anterior else densityP)\n",
    "    clusterLabels = (clusterLabelsA if anterior else clusterLabelsP)\n",
    "    arrWatershed = (arrWatershedA if anterior else arrWatershedP)\n",
    "\n",
    "    # Plot density\n",
    "    ax.imshow(np.flip(density, axis=0), extent=(0, 200, 0, 200), cmap='gray_r')\n",
    "\n",
    "    # Plot cluster boundaries\n",
    "    for z in range(2):\n",
    "        for k, clusterIDsKey in enumerate([x for x in clusterLabels if x != 'noisy']):\n",
    "            clusterIDs = clusterLabels[clusterIDsKey]\n",
    "            # Plot clusters to highlight\n",
    "            mask = None\n",
    "            for exID, clusterID in enumerate(clusterIDs):\n",
    "                _mask = (arrWatershed[:,:,0,1] == clusterID)\n",
    "                # Merge masks\n",
    "                mask = _mask if mask is None else (mask | _mask)\n",
    "\n",
    "            # Split masks into contiguous submasks\n",
    "            maskLabeled = label(binary_dilation(binary_erosion(mask, iterations=1), iterations=1))\n",
    "            maskLabeledBg = np.max([np.sum(maskLabeled == x) for x in np.unique(maskLabeled)])\n",
    "            isLabeled = False\n",
    "            for maskID in np.unique(maskLabeled):\n",
    "                if np.sum(maskLabeled == maskID) != maskLabeledBg:\n",
    "                    mask = (maskLabeled == maskID)\n",
    "                    mask[:25,:] = False\n",
    "                    mask[175:,:] = False\n",
    "                    mask[:,:25] = False\n",
    "                    mask[:,175:] = False\n",
    "                    pts = maskToPerimeter(mask)\n",
    "                    if pts is not None:\n",
    "                        ax.plot(pts[:,1], pts[:,0], linewidth=2, \\\n",
    "                            color='#aaaaaa', linestyle='--', zorder=5)\n",
    "                        clusterIDsKeyBase = re.search('.*(?=-[0-9]*)', clusterIDsKey).group(0)\n",
    "                        ax.fill(pts[:,1], pts[:,0], linewidth=1, \\\n",
    "                            edgecolor=COLORS_CLUSTERS[clusterIDsKeyBase], \n",
    "                            facecolor=COLORS_CLUSTERS[clusterIDsKeyBase] + '22', zorder=5)\n",
    "                        isLabeled = True\n",
    "\n",
    "    # Arrow Colormap\n",
    "    cm = plt.get_cmap('cet_CET_L18')\n",
    "\n",
    "    # Sort arrows to plot by increasing thickness\n",
    "    ijs = np.array(sorted(np.argwhere(transitionsPlt), key=lambda x: transitionsPlt[x[0],x[1]]))\n",
    "    \n",
    "    for (i, j) in ijs:\n",
    "        if transitionsPlt[i,j] > 0.05 and transitionsRate[i,j] >= 10:\n",
    "            ax.annotate(\"\",\n",
    "                xytext=(peaks[i,1],peaks[i,0]), xycoords='data',\n",
    "                xy=(peaks[j,1],peaks[j,0]), textcoords='data',\n",
    "                arrowprops=dict(fc=cm(int(transitionsPlt[i,j] * 255.0)), \n",
    "                                mutation_scale=transitionsPlt[i,j] * 10, \n",
    "                                ec='#222222',\n",
    "                                linewidth=0.3,\n",
    "                                width=transitionsPlt[i,j] * 10,\n",
    "                                headwidth=5 + transitionsPlt[i,j] * 10,\n",
    "                                connectionstyle=\"arc3, rad=-0.2\",\n",
    "                                shrinkA=15, shrinkB=15), zorder=10)\n",
    "\n",
    "    for p in range(peaks.shape[0]):\n",
    "        pass #ax.scatter(peaks[p,1], peaks[p,0], color='black', s=10)\n",
    "    \n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax[0].set_title('Anterior Transitions')\n",
    "plot(ax[0], True)\n",
    "ax[0].set_xlim(25, 175)\n",
    "ax[0].set_ylim(25, 175)\n",
    "\n",
    "ax[1].set_title('Posterior Transitions')\n",
    "plot(ax[1], False)\n",
    "ax[1].set_xlim(25, 175)\n",
    "ax[1].set_ylim(25, 175)\n",
    "\n",
    "cbar_ax = fig.add_axes([0.99, 0.3, 0.02, 0.4])\n",
    "cb = mpl.colorbar.ColorbarBase(\n",
    "    cbar_ax, cmap=plt.get_cmap('cet_CET_L18'),\n",
    "    orientation='vertical', ticks=[0, 1], \n",
    "    label='Transition Probability Normalized to Maximum')\n",
    "cb.ax.set_yticklabels(['0', '100%'])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('C:/Users/acorver/Desktop/paper-figures/transitions_arrows_style2_{}{}z2.pdf'.format(\n",
    "    probThreshold, '_mergemanual' if MERGE_MANUAL else ''), bbox_inches = 'tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
